{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyarrow import parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_col_name_dict(\n",
    "    curr_names: list[str],\n",
    "    new_names: list[str]\n",
    ") -> dict[str: str]:\n",
    "    \"\"\"Maps raw data column tags to readable titles.\n",
    "\n",
    "    Args:\n",
    "        curr_names: The tags identifying data subset of interest.\n",
    "        new_names: List of names to replace tags as column headers.\n",
    "\n",
    "    Returns: Dictionary\n",
    "    \"\"\"\n",
    "    col_names_dict = {\n",
    "        \"NAME\": \"State\",\n",
    "        \"S1501_C01_006E\": \"Total Pop.\",\n",
    "        \"S1501_C01_006M\": \"Total Pop. ME\",\n",
    "    }\n",
    "    # Creates a duplicate for each name distinguished by a suffix.\n",
    "    new_names = [item for name in new_names for item in (name, f\"{name} ME\")]\n",
    "    col_names_dict |= {k: v for k, v in zip(curr_names[3:], new_names)}\n",
    "    return col_names_dict\n",
    "\n",
    "def cols_to_keep(year: int) -> list[str]:\n",
    "    \"\"\"Gets column unique tags of interest.\n",
    "\n",
    "    Args:\n",
    "        year: Year is necessary due to certain data being retagged after 2014.\n",
    "\n",
    "    Returns: The column tags used to select a subset of the raw data.\n",
    "    \"\"\"\n",
    "    base = [\"NAME\", \"S1501_C01_006E\", \"S1501_C01_006M\"]\n",
    "    adjusted = [\n",
    "        f\"S1501_C0{(year > 2014) + 1}_0{str(n).zfill(2)}{suffix}\"\n",
    "        for n in range(7, 14)\n",
    "        for suffix in [\"E\", \"M\"]\n",
    "    ]\n",
    "    return base + adjusted\n",
    "\n",
    "def gen_edu_df(year: int) -> pd.DataFrame:\n",
    "    \"\"\"Generates dataframe from raw educational attainment csv data.\n",
    "    Contains state-level percentages (and associated margin of error) for\n",
    "    each ordinal education category of age group 25 and over.\n",
    "\n",
    "    Args:\n",
    "        year: Ranges from 2010-2021 excluding 2020 (due to quality issues\n",
    "            stemming from the covid pandemic).\n",
    "\n",
    "    Returns: Trimmed dataset.\n",
    "    \"\"\"\n",
    "    path = (\n",
    "        f\"../raw-data/ACSSTEducationalAttainment2010-2021\"\n",
    "        f\"/ACSST1Y{year}.S1501-Data.csv\"\n",
    "    )\n",
    "    new_names = [\n",
    "        \"< 9th Grade\", \"9-12, no diploma\", \"HS graduate (or equivalent)\",\n",
    "        \"Some college, no degree\", \"Associate's degree\", \"Bachelor's degree\",\n",
    "        \"Graduate or professional degree\",\n",
    "    ]\n",
    "    cols = cols_to_keep(year)\n",
    "    edu_df = (\n",
    "        pd\n",
    "        .read_csv(path, usecols=cols, skiprows=[1], dtype={\"NAME\": \"category\"})\n",
    "        .rename(columns=gen_col_name_dict(cols, new_names))\n",
    "    )\n",
    "    return edu_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_ins_df(year: int) -> pd.DataFrame:\n",
    "    \"\"\"Generates dataframe from raw insurance coverage csv data.\n",
    "    Contains state-level percentage (including margin of error) of\n",
    "    the uninsured for ages 18-64 (filtering was later revised to 19-64\n",
    "    starting in 2017).\n",
    "    \n",
    "    Args:\n",
    "        year: Ranges from 2010-2021 excluding 2020 (due to quality issues\n",
    "            stemming from the covid pandemic).\n",
    "\n",
    "    Returns: Trimmed dataset.\n",
    "    \"\"\"\n",
    "    path = (\n",
    "        f\"../raw-data/ACSSTInsuranceCoverage2010-2021\"\n",
    "        f\"/ACSST1Y{year}.S2701-Data.csv\"\n",
    "    )\n",
    "    if year > 2017:\n",
    "        cidx, ridx = 5, 12\n",
    "    elif year > 2014:\n",
    "        cidx, ridx = 5, 5\n",
    "    else:\n",
    "        cidx, ridx = 3, 3\n",
    "    adjusted = [\n",
    "        f\"S2701_C0{cidx}_0{str(ridx).zfill(2)}{suffix}\"\n",
    "        for suffix in [\"E\", \"M\"]\n",
    "    ]\n",
    "    cols = [\"NAME\"] + adjusted\n",
    "    col_names = [\"State\", \"% Uninsured\", \"% Uninsured ME\"]\n",
    "    col_names_dict = {k: v for k, v in zip(cols, col_names)}\n",
    "    inscov_df = (\n",
    "        pd\n",
    "        .read_csv(path, usecols=cols, skiprows=[1], dtype={\"NAME\": \"category\"})\n",
    "        .rename(columns=col_names_dict)\n",
    "    )\n",
    "    return inscov_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_pov_df(year: int) -> pd.DataFrame:\n",
    "    \"\"\"Generates dataframe from raw poverty csv data.\n",
    "    Contains state-level percentage (including margin of error) of\n",
    "    those beneath the poverty line of ages ranging 18-64.\n",
    "\n",
    "    Args:\n",
    "        year: Ranges from 2010-2021 excluding 2020 (due to quality issues\n",
    "            stemming from the covid pandemic).\n",
    "\n",
    "    Returns: Trimmed dataset.\n",
    "    \"\"\"\n",
    "    path = f\"../raw-data/ACSSTPoverty2010-2021/ACSST1Y{year}.S1701-Data.csv\"\n",
    "    adjusted = [\n",
    "        f\"S1701_C03_00{(year > 2014) * 2 + 4}{suffix}\" for suffix in [\"E\", \"M\"]\n",
    "    ]\n",
    "    cols = [\"NAME\"] + adjusted\n",
    "    col_names = [\"State\", \"% below poverty\", \"% below poverty ME\"]\n",
    "    col_names_dict = {k: v for k, v in zip(cols, col_names)}\n",
    "    poverty_df = (\n",
    "        pd\n",
    "        .read_csv(path, usecols=cols, skiprows=[1], dtype={\"NAME\": \"category\"})\n",
    "        .rename(columns=col_names_dict)\n",
    "    )\n",
    "    return poverty_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def edu_attainment_donut(edu_df, year, state):\n",
    "#     \"\"\"\n",
    "#     \"\"\"\n",
    "#     data = edu_df.query(f\"State == '{state}'\")[new_names].values[0]\n",
    "#     plt.pie(data, labels=new_names, wedgeprops={'linewidth': 1.5, 'edgecolor': 'white'})\n",
    "#     plt.gcf().gca().add_artist(plt.Circle((0, 0), 0.65, color='white'))\n",
    "#     plt.title(f\"{state}: {year}\")\n",
    "#     plt.show()\n",
    "\n",
    "# years = [n for n in range(2010, 2022) if n != 2020]\n",
    "# #for year in years:\n",
    "#     #edu_attainment_donut(year, \"California\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_rand_df() -> pd.DataFrame:\n",
    "    \"\"\"Generates RAND dataframe of select features from raw excel data.\n",
    "    State-level estimated firearm ownership percentage\n",
    "    (including standard error). Also contains binary columns signifying\n",
    "    state universal background checks and permit policies.\n",
    "    Lastly, restricts year range to that similar of the other datasets.\n",
    "    Ranges from 2000-2016.\n",
    "\n",
    "    Returns: Trimmed dataset.\n",
    "    \"\"\"\n",
    "    path = (\n",
    "        \"../raw-data/RAND_TL354.database/\"\n",
    "        \"TL-354-State-Level Estimates of Household Firearm Ownership.xlsx\"\n",
    "    )\n",
    "    cols = (\"Year\", \"STATE\", \"HFR\", \"HFR_se\", \"universl\", \"permit\")\n",
    "    dtype_dict = {\n",
    "        \"Year\": np.uint16,\n",
    "        \"STATE\": \"category\",\n",
    "        \"universl\": bool,\n",
    "        \"permit\": bool,\n",
    "    }\n",
    "    rand_df = pd.read_excel(\n",
    "        path,\n",
    "        sheet_name=1,\n",
    "        usecols=cols,\n",
    "        dtype=dtype_dict,\n",
    "    ).query(\"Year >= 2000\").rename(columns={\"STATE\": \"State\"})\n",
    "    return rand_df\n",
    "\n",
    "#filtered_df = rand_df.query(\"Year >= 2010 & STATE in ['Missouri', 'Iowa']\").copy()\n",
    "#filtered_df[\"STATE\"] = filtered_df[\"STATE\"].cat.remove_unused_categories()\n",
    "#sns.lineplot(filtered_df, x=\"Year\", y=\"HFR\", hue=\"STATE\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_nsduh_df(year: int) -> pd.DataFrame:\n",
    "    \"\"\"Generates merged dataframe based off of two tables from NSDUH raw data.\n",
    "    The two datasets in question are as followed:\n",
    "        \"Needing But Not Receiving Treatment at a Specialty Facility \n",
    "            for Substance Use in the Past Year\"\n",
    "        \"Serious Mental Illness in the Past Year\"\n",
    "    Both labeled as percentages and for ages 18 or older.\n",
    "\n",
    "    Args:\n",
    "        year: Year is necessary due to reorganization of the\n",
    "            excel sheet tables. There are two such instances,\n",
    "            one in 2017 and another in 2019. Ranges from 2016-2019.\n",
    "\n",
    "    Returns: A multiindex dataframe.\n",
    "    \"\"\"\n",
    "    path = \"../raw-data/NSDUH2016-2019/\"\n",
    "    ext = f\"NSDUHsaeExcelTabs{year}.xlsx\"\n",
    "    if year < 2017:\n",
    "        sheets = [25, 26]\n",
    "        path += ext\n",
    "    elif year < 2019:\n",
    "        sheets = [26, 27]\n",
    "        path += ext\n",
    "    else:\n",
    "        sheets = [26, 28]\n",
    "        path += f\"{year}NSDUHsaeExcelTabs.xlsx\"\n",
    "    cols = [\n",
    "        \"State\", \"18 or Older\\nEstimate\", \"18 or Older\\n95% CI (Lower)\",\n",
    "        \"18 or Older\\n95% CI (Upper)\"\n",
    "    ]\n",
    "    df_dict = pd.read_excel(path,\n",
    "        sheet_name=sheets,\n",
    "        usecols=cols,\n",
    "        skiprows=[n for n in range(11) if n != 5],\n",
    "        dtype={\"State\": \"category\"}\n",
    "    )\n",
    "    sub_use_df, m_illness_df = df_dict.values()\n",
    "    combined = sub_use_df.merge(m_illness_df, on=\"State\")\n",
    "    state_multidx = pd.MultiIndex.from_arrays([cols[:1], [\"\"]])\n",
    "    table_multidx = pd.MultiIndex.from_product(\n",
    "        [['Needing Treatment for Substance Use', 'Serious Mental Illness'],\n",
    "        cols[1:]]\n",
    "    )\n",
    "    combined.columns = state_multidx.append(table_multidx)\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE RAW XLSX WILL NOT BE INCLUDED TO RESPECT THE CREATOR'S WISHES.\n",
    "# REFINED FILE WILL REMAIN FOR ACCESS, AS IT IS MUCH MORE LIMITED IN SCOPE.\n",
    "def gen_shootings_df() -> pd.DataFrame:\n",
    "    \"\"\"Generates dataframe from select features of the full school shootings\n",
    "    database. Contains dates and exact coordinate locations for visualization\n",
    "    purposes and statistics on casualties. Also includes motive of attack\n",
    "    via the Target column. This information is used to lightly filter\n",
    "    dataset further by excluding the \"neither\" category which is often tied\n",
    "    to accidental or self-injury related incidents. Further filtering\n",
    "    is done by restricing the time interval similar to the other datasets.\n",
    "\n",
    "    Returns: Trimmed dataset.\n",
    "    \"\"\"\n",
    "    path = (\n",
    "        \"../raw-data/Public v3.1 K-12 School Shooting Database \"\n",
    "        \"(April 17 2023 with GIS).xlsx\"\n",
    "    )\n",
    "    cols = (\n",
    "        \"Date\", \"Victims_Killed\", \"Victims_Wounded\",\n",
    "        \"Number_Victims\", \"Targets\", \"State\", \"LAT\", \"LNG\"\n",
    "    )\n",
    "    shootings_df = pd.read_excel(\n",
    "        path,\n",
    "        sheet_name=1,\n",
    "        usecols=cols,\n",
    "        dtype={\n",
    "            \"Victims_Killed\": np.uint16,\n",
    "            \"Victims_Wounded\": np.uint16,\n",
    "            \"Number_Victims\": np.uint16,\n",
    "            \"State\": \"category\",\n",
    "            \"Targets\": \"category\",\n",
    "        }\n",
    "    ).query(\"Targets != 'Neither' and Date >= '2000-01-01'\")\n",
    "    return shootings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_state_to_abbrev = {\n",
    "    \"Alabama\": \"AL\",\n",
    "    \"Alaska\": \"AK\",\n",
    "    \"Arizona\": \"AZ\",\n",
    "    \"Arkansas\": \"AR\",\n",
    "    \"California\": \"CA\",\n",
    "    \"Colorado\": \"CO\",\n",
    "    \"Connecticut\": \"CT\",\n",
    "    \"Delaware\": \"DE\",\n",
    "    \"Florida\": \"FL\",\n",
    "    \"Georgia\": \"GA\",\n",
    "    \"Hawaii\": \"HI\",\n",
    "    \"Idaho\": \"ID\",\n",
    "    \"Illinois\": \"IL\",\n",
    "    \"Indiana\": \"IN\",\n",
    "    \"Iowa\": \"IA\",\n",
    "    \"Kansas\": \"KS\",\n",
    "    \"Kentucky\": \"KY\",\n",
    "    \"Louisiana\": \"LA\",\n",
    "    \"Maine\": \"ME\",\n",
    "    \"Maryland\": \"MD\",\n",
    "    \"Massachusetts\": \"MA\",\n",
    "    \"Michigan\": \"MI\",\n",
    "    \"Minnesota\": \"MN\",\n",
    "    \"Mississippi\": \"MS\",\n",
    "    \"Missouri\": \"MO\",\n",
    "    \"Montana\": \"MT\",\n",
    "    \"Nebraska\": \"NE\",\n",
    "    \"Nevada\": \"NV\",\n",
    "    \"New Hampshire\": \"NH\",\n",
    "    \"New Jersey\": \"NJ\",\n",
    "    \"New Mexico\": \"NM\",\n",
    "    \"New York\": \"NY\",\n",
    "    \"North Carolina\": \"NC\",\n",
    "    \"North Dakota\": \"ND\",\n",
    "    \"Ohio\": \"OH\",\n",
    "    \"Oklahoma\": \"OK\",\n",
    "    \"Oregon\": \"OR\",\n",
    "    \"Pennsylvania\": \"PA\",\n",
    "    \"Rhode Island\": \"RI\",\n",
    "    \"South Carolina\": \"SC\",\n",
    "    \"South Dakota\": \"SD\",\n",
    "    \"Tennessee\": \"TN\",\n",
    "    \"Texas\": \"TX\",\n",
    "    \"Utah\": \"UT\",\n",
    "    \"Vermont\": \"VT\",\n",
    "    \"Virginia\": \"VA\",\n",
    "    \"Washington\": \"WA\",\n",
    "    \"West Virginia\": \"WV\",\n",
    "    \"Wisconsin\": \"WI\",\n",
    "    \"Wyoming\": \"WY\",\n",
    "    \"District of Columbia\": \"DC\",\n",
    "    \"American Samoa\": \"AS\",\n",
    "    \"Guam\": \"GU\",\n",
    "    \"Northern Mariana Islands\": \"MP\",\n",
    "    \"Puerto Rico\": \"PR\",\n",
    "    \"United States Minor Outlying Islands\": \"UM\",\n",
    "    \"U.S. Virgin Islands\": \"VI\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_preprocessing() -> tuple[pd.DataFrame]:\n",
    "    \"\"\"Processes dataframes for exporting. Degree of processing varies\n",
    "    depending on raw data. Dataframes generated on individual year basis\n",
    "    are combined into a single full time range dataframe. ACSST dataframes\n",
    "    (edu, ins, pov) are also merged due to sharing same states and timespans.\n",
    "    Each dataframe then has its state column converted to state codes for\n",
    "    ease of use in plotly.\n",
    "\n",
    "    Returns: All processed dataframes as a tuple. Note that second element\n",
    "        (nsduh_df) is unique due to being the only multiindex df.\n",
    "    \"\"\"\n",
    "    full_dfs = ([], [], [], [])\n",
    "    years = np.array([year for year in range(2010, 2022)], dtype=np.uint16)\n",
    "    # Stores all yearly chunks into individual lists for each per year dataset.\n",
    "    for year in years:\n",
    "        if year != 2020:\n",
    "            df_lst = [gen_edu_df(year), gen_ins_df(year), gen_pov_df(year)]\n",
    "            for i, df in enumerate(df_lst):\n",
    "                df[\"Year\"] = year\n",
    "                full_dfs[i].append(df)\n",
    "        if 2015 < year < 2020:\n",
    "            nsduh_df = gen_nsduh_df(year)\n",
    "            nsduh_df[\"Year\"] = year\n",
    "            full_dfs[len(df_lst)].append(nsduh_df)\n",
    "    # Concat yearly dfs into single full time range df\n",
    "    # for each per year dataset collection.\n",
    "    concated_lst = []\n",
    "    for df_sublst in full_dfs:\n",
    "        concated_lst.append(pd.concat(df_sublst))\n",
    "    acsst_df = concated_lst[0]\n",
    "    # Chain merge all ACSST dfs into a single master df.\n",
    "    for i in range(1, len(concated_lst) - 1):\n",
    "        acsst_df = acsst_df.merge(concated_lst[i], on=[\"Year\", \"State\"])\n",
    "    for df in [acsst_df, concated_lst[-1], rand_df := gen_rand_df()]:\n",
    "        df[\"State\"] = df[\"State\"].cat.rename_categories(us_state_to_abbrev)\n",
    "    return acsst_df, concated_lst[-1], rand_df, gen_shootings_df()\n",
    "\n",
    "def export_refined() -> None:\n",
    "    \"\"\"Saves final Dataframes to be used in data analysis.\n",
    "    \"\"\"\n",
    "    out = [f\"refined-{name}\" for name in [\"ACSST\", \"NSDUH\", \"RAND\", \"SSDB\"]]\n",
    "    for df, path in zip(export_preprocessing(), out):\n",
    "        df.to_parquet(f\"../refined-data/{path}.parquet\")\n",
    "\n",
    "export_refined()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
